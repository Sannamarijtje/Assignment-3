{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8516b225",
   "metadata": {},
   "source": [
    "# Week 10: Data exploration & Replication of baseline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d86664e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "032a786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df_attributes = pandas.read_csv('DATA/attributes.csv')\n",
    "df_products = pandas.read_csv('DATA/product_descriptions.csv')\n",
    "df_train = pandas.read_csv('DATA/train.csv', encoding='latin1')\n",
    "df_test = pandas.read_csv('DATA/test.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8447533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74067 entries, 0 to 74066\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             74067 non-null  int64  \n",
      " 1   product_uid    74067 non-null  int64  \n",
      " 2   product_title  74067 non-null  object \n",
      " 3   search_term    74067 non-null  object \n",
      " 4   relevance      74067 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 2.8+ MB\n",
      "None\n",
      "(74067, 5)\n",
      "53489\n",
      "product_title\n",
      "Lithonia Lighting All Season 4 ft. 2-Light Grey T8 Strip Fluorescent Shop Light                                          21\n",
      "Pressure-Treated Timber #2 Southern Yellow Pine (Common: 4 in. x 4 in. x 8 ft.; Actual: 3.56 in. x 3.56 in. x 96 in.)    21\n",
      "2 in. x 4 in. x 96 in. Premium Kiln-Dried Whitewood Stud                                                                 18\n",
      "Ryobi ONE+ 18-Volt Lithium-Ion Ultimate Combo Kit (6-Tool)                                                               17\n",
      "Custom Building Products VersaBond Gray 50 lb. Fortified Thin-Set Mortar                                                 17\n",
      "Ryobi ONE+ 18-Volt Lithium-Ion Cordless Drill/Driver and Impact Driver Kit (2-Tool)                                      17\n",
      "Whirlpool Gold Series Top Control Dishwasher in Monochromatic Stainless Steel with Silverware Spray                      15\n",
      "Whirlpool 1.7 cu. ft. Over the Range Microwave in Stainless Steel                                                        14\n",
      "WeatherShield 2 in. x 4 in. x 8 ft. #2 Prime Prime Pressure-Treated Lumber                                               14\n",
      "23/32 in. x 4 ft. x 8 ft. RTD Sheathing Syp                                                                              14\n",
      "Name: count, dtype: int64\n",
      "2.3816337910270433 2.33 0.5339839484172094\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "print(df_train.info())\n",
    "print(df_train.shape)\n",
    "print(len(df_train['product_title'].unique()))\n",
    "print(df_train['product_title'].value_counts().head(10))\n",
    "print(df_train['relevance'].mean(), df_train['relevance'].median(), df_train['relevance'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ce2141b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a histogram of the relevance values\n",
    "bins = [1, 1.33, 1.66, 2, 2.33, 2.66, 3]\n",
    "\n",
    "plt.hist(df_train['relevance'], bins=np.array(bins) - 0.15, color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.xticks(bins, labels=[str(b) for b in bins])\n",
    "\n",
    "plt.title('Histogram of Relevance Values')\n",
    "plt.xlabel('Relevance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d941182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_uid\n",
      "195932.0    88\n",
      "100532.0    80\n",
      "119037.0    79\n",
      "186482.0    79\n",
      "144095.0    78\n",
      "Name: count, dtype: int64\n",
      "['Simpson Strong-Tie' 'BEHR Premium Textured DeckOver' 'STERLING' ...\n",
      " 'Woolite' \"Durham's Rock Hard\" 'Variflex']\n",
      "value\n",
      "Unbranded                     2954\n",
      "Hampton Bay                   1723\n",
      "KOHLER                        1389\n",
      "Everbilt                      1381\n",
      "Home Decorators Collection    1275\n",
      "GE                             987\n",
      "Prime-Line                     931\n",
      "Crown Bolt                     878\n",
      "Delta                          853\n",
      "DEWALT                         675\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the brand names\n",
    "print(df_attributes['product_uid'].value_counts().head(5))\n",
    "filtered_df = df_attributes[df_attributes[\"name\"].str.contains('Brand Name', na=False)]\n",
    "print(filtered_df[\"value\"].unique())\n",
    "print(filtered_df[\"value\"].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8c3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  product_uid  relevance  len_of_query  word_in_title  \\\n",
      "0   2       100001       3.00             2              1   \n",
      "1   3       100001       2.50             2              1   \n",
      "2   9       100002       3.00             2              1   \n",
      "3  16       100005       2.33             3              1   \n",
      "4  17       100005       2.67             3              3   \n",
      "\n",
      "   word_in_description  \n",
      "0                    1  \n",
      "1                    1  \n",
      "2                    1  \n",
      "3                    1  \n",
      "4                    2  \n",
      "       id  product_uid  relevance  len_of_query  word_in_title  \\\n",
      "74067   1       100001        NaN             3              0   \n",
      "74068   4       100001        NaN             3              1   \n",
      "74069   5       100001        NaN             3              1   \n",
      "74070   6       100001        NaN             3              2   \n",
      "74071   7       100001        NaN             4              2   \n",
      "\n",
      "       word_in_description  \n",
      "74067                    1  \n",
      "74068                    1  \n",
      "74069                    1  \n",
      "74070                    2  \n",
      "74071                    2  \n"
     ]
    }
   ],
   "source": [
    "# Baseline model from Yao-Jen Chang\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "df_train = pd.read_csv('DATA/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('DATA/test.csv', encoding=\"ISO-8859-1\")\n",
    "# df_attr = pd.read_csv('DATA/attributes.csv')\n",
    "df_pro_desc = pd.read_csv('DATA/product_descriptions.csv')\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "\n",
    "def str_stemmer(s):\n",
    "\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n",
    "\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "\n",
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train.drop(['id','relevance'],axis=1).values\n",
    "X_test = df_test.drop(['id','relevance'],axis=1).values\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31237e",
   "metadata": {},
   "source": [
    "# Week 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63f8f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13ccb96",
   "metadata": {},
   "source": [
    "## Adjusted baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc4405b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.4817214529959809\n"
     ]
    }
   ],
   "source": [
    "# Adjusted baseline model\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Read in the data\n",
    "df_train = pd.read_csv('DATA/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('DATA/test.csv', encoding=\"ISO-8859-1\")\n",
    "# df_attr = pd.read_csv('DATA/attributes.csv')\n",
    "df_pro_desc = pd.read_csv('DATA/product_descriptions.csv')\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "\n",
    "# Function to stem words and find common words\n",
    "def str_stemmer(s):\n",
    "\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "# Concatenate train and test data\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n",
    "\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "\n",
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "\n",
    "# Split the training data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','relevance'],axis=1).values, df_train['relevance'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the RMSE\n",
    "print(\"RMSE: \", root_mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa832c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.4817214529959809\n",
      "(74067, 6)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','relevance'],axis=1).values, df_train['relevance'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the RMSE\n",
    "print(\"RMSE: \", root_mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e04f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.512613133984399\n"
     ]
    }
   ],
   "source": [
    "# Adjusted baseline model (without stemming)\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Read in the data\n",
    "df_train = pd.read_csv('DATA/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('DATA/test.csv', encoding=\"ISO-8859-1\")\n",
    "# df_attr = pd.read_csv('DATA/attributes.csv')\n",
    "df_pro_desc = pd.read_csv('DATA/product_descriptions.csv')\n",
    "\n",
    "num_train = df_train.shape[0]\n",
    "\n",
    "# Function to stem words and find common words\n",
    "def str_stemmer(s):\n",
    "\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "# Concatenate train and test data\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].astype(str)\n",
    "df_all['product_title'] = df_all['product_title'].astype(str)\n",
    "df_all['product_description'] = df_all['product_description'].astype(str)\n",
    "\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n",
    "\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "\n",
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "\n",
    "# Split the training data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','relevance'],axis=1).values, df_train['relevance'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the RMSE\n",
    "print(\"RMSE: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ddf37",
   "metadata": {},
   "source": [
    "## Feature 1: TF IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15870528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanna\\anaconda3\\envs\\DS3\\Lib\\site-packages\\sklearn\\utils\\validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sanna\\anaconda3\\envs\\DS3\\Lib\\site-packages\\sklearn\\utils\\validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE after TF-IDF:  0.5225794736088272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Read in the data\n",
    "df_train = pd.read_csv('DATA/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('DATA/product_descriptions.csv')\n",
    "\n",
    "df_all = pd.merge(df_train, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "# Select relevant text features for TF-IDF\n",
    "text_features = df_all[['search_term', 'product_title', 'product_description']].fillna(\"\")\n",
    "\n",
    "# Apply TF-IDF to capture text importance\n",
    "vectorizer = TfidfVectorizer(max_features=2500, stop_words='english', lowercase=True, min_df=4)\n",
    "tfidf_matrix = vectorizer.fit_transform(text_features['search_term'] + \" \" + text_features['product_title'] + \" \" + text_features['product_description'])\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate TF-IDF features with original numerical features\n",
    "df_all_tfidf = pd.concat([df_all.drop(['search_term', 'product_title', 'product_description'], axis=1), tfidf_df], axis=1)\n",
    "\n",
    "# Split the training data into training and test sets with TF-IDF features\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_all_tfidf.drop(['id', 'relevance'], axis=1), df_all_tfidf['relevance'], test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the RMSE with TF-IDF\n",
    "print(\"RMSE after TF-IDF: \", root_mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75323925",
   "metadata": {},
   "source": [
    "## Feature 2: Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3b1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE after Jaccard Similarity:  0.5049099506146119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Create a function to calculate Jaccard Similarity\n",
    "def jaccard_similarity(str1, str2):\n",
    "    set1 = set(str1.lower().split())\n",
    "    set2 = set(str2.lower().split())\n",
    "    return len(set1 & set2) / len(set1 | set2) if (set1 | set2) else 0\n",
    "\n",
    "# Read in the data\n",
    "df_train = pd.read_csv('DATA/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('DATA/product_descriptions.csv')\n",
    "df_all = pd.merge(df_train, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "# Calculate Jaccard Similarity features\n",
    "df_all['jaccard_title'] = df_all.apply(lambda x: jaccard_similarity(str(x['search_term']), str(x['product_title'])), axis=1)\n",
    "df_all['jaccard_description'] = df_all.apply(lambda x: jaccard_similarity(str(x['search_term']), str(x['product_description'])), axis=1)\n",
    "\n",
    "# Split the dataset, including Jaccard features\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_all.drop(['id', 'relevance', 'search_term', 'product_title', 'product_description'], axis=1), \n",
    "    df_all['relevance'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Retrain the model with Jaccard features\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the RMSE with Jaccard features\n",
    "print(\"RMSE after Jaccard Similarity: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfda3c0",
   "metadata": {},
   "source": [
    "## Feature 3: Word order importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebe3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE after word order importance:  0.515381969586403\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "df_train = pd.read_csv('DATA/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('DATA/product_descriptions.csv')\n",
    "df_all = pd.merge(df_train, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "# Function for Word Order Importance\n",
    "def word_order_importance(search_term, product_title):\n",
    "    search_words = search_term.lower().split()\n",
    "    title_words = product_title.lower().split()\n",
    "    \n",
    "    match_count = 0\n",
    "    for i in range(len(search_words) - 1): \n",
    "        search_pair = \" \".join(search_words[i:i+2]) \n",
    "        title_text = \" \".join(title_words)\n",
    "        if search_pair in title_text:\n",
    "            match_count += 1  \n",
    "\n",
    "    return match_count / max(1, len(search_words) - 1)  \n",
    "\n",
    "df_all['word_order_score'] = df_all.apply(lambda x: word_order_importance(str(x['search_term']), str(x['product_title'])), axis=1)\n",
    "\n",
    "# Split the dataset, including Word Order Score\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_all.drop(['id', 'relevance', 'search_term', 'product_title', 'product_description'], axis=1), \n",
    "    df_all['relevance'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Retrain the model with Word Order Score\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the RMSE with word order importance\n",
    "print(\"RMSE after word order importance: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919c37d",
   "metadata": {},
   "source": [
    "# Week 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9af5e4",
   "metadata": {},
   "source": [
    "## Regression 1 - Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a34a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.5277182312311637\n"
     ]
    }
   ],
   "source": [
    "# Elastic net\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','relevance'],axis=1).values, df_train['relevance'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "elnet = ElasticNet(random_state=0)\n",
    "elnet.fit(X_train, y_train)\n",
    "y_pred = elnet.predict(X_test)\n",
    "\n",
    "# Print the RMSE\n",
    "rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41546be0",
   "metadata": {},
   "source": [
    "## Regression 2 - LARS Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ce777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.49269803166494186\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','relevance'],axis=1).values, df_train['relevance'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "lars = linear_model.LassoLars(alpha=0.01, random_state=0) \n",
    "lars.fit(X_train, y_train)\n",
    "y_pred = lars.predict(X_test)\n",
    "\n",
    "# Print the RMSE\n",
    "print(\"RMSE: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843bc687",
   "metadata": {},
   "source": [
    "## Regression 3 - Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "542b5696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.4924494911226799\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','relevance'],axis=1).values, df_train['relevance'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "bayesianridge = linear_model.BayesianRidge() \n",
    "bayesianridge.fit(X_train, y_train)\n",
    "y_pred = bayesianridge.predict(X_test)\n",
    "\n",
    "# Print the RMSE\n",
    "print(\"RMSE: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c054a",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2338e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-0.4805  \u001b[39m | \u001b[39m8.116    \u001b[39m | \u001b[39m19.11    \u001b[39m | \u001b[39m159.8    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-0.4825  \u001b[39m | \u001b[39m12.37    \u001b[39m | \u001b[39m4.808    \u001b[39m | \u001b[39m73.4     \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-0.5073  \u001b[39m | \u001b[39m2.104    \u001b[39m | \u001b[39m17.59    \u001b[39m | \u001b[39m140.2    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-0.4853  \u001b[39m | \u001b[39m14.45    \u001b[39m | \u001b[39m2.371    \u001b[39m | \u001b[39m195.5    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-0.4885  \u001b[39m | \u001b[39m16.82    \u001b[39m | \u001b[39m5.822    \u001b[39m | \u001b[39m77.27    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-0.4885  \u001b[39m | \u001b[39m4.485    \u001b[39m | \u001b[39m7.476    \u001b[39m | \u001b[39m128.7    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-0.4807  \u001b[39m | \u001b[39m9.207    \u001b[39m | \u001b[39m7.242    \u001b[39m | \u001b[39m141.8    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-0.4984  \u001b[39m | \u001b[39m3.65     \u001b[39m | \u001b[39m7.259    \u001b[39m | \u001b[39m105.0    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-0.4808  \u001b[39m | \u001b[39m9.665    \u001b[39m | \u001b[39m16.13    \u001b[39m | \u001b[39m79.95    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-0.481   \u001b[39m | \u001b[39m10.77    \u001b[39m | \u001b[39m12.66    \u001b[39m | \u001b[39m56.97    \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-0.481   \u001b[39m | \u001b[39m10.23    \u001b[39m | \u001b[39m12.39    \u001b[39m | \u001b[39m56.56    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-0.4806  \u001b[39m | \u001b[39m7.018    \u001b[39m | \u001b[39m13.19    \u001b[39m | \u001b[39m68.92    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-0.4874  \u001b[39m | \u001b[39m15.99    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m146.6    \u001b[39m |\n",
      "| \u001b[35m14       \u001b[39m | \u001b[35m-0.4804  \u001b[39m | \u001b[35m8.137    \u001b[39m | \u001b[35m4.151    \u001b[39m | \u001b[35m63.18    \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-0.519   \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m5.067    \u001b[39m | \u001b[39m73.62    \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-0.4829  \u001b[39m | \u001b[39m13.04    \u001b[39m | \u001b[39m9.588    \u001b[39m | \u001b[39m65.7     \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-0.4818  \u001b[39m | \u001b[39m12.07    \u001b[39m | \u001b[39m18.33    \u001b[39m | \u001b[39m72.0     \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-0.4806  \u001b[39m | \u001b[39m7.555    \u001b[39m | \u001b[39m18.16    \u001b[39m | \u001b[39m63.33    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-0.4839  \u001b[39m | \u001b[39m13.46    \u001b[39m | \u001b[39m2.099    \u001b[39m | \u001b[39m56.43    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-0.4808  \u001b[39m | \u001b[39m10.65    \u001b[39m | \u001b[39m18.79    \u001b[39m | \u001b[39m168.8    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-0.4805  \u001b[39m | \u001b[39m8.636    \u001b[39m | \u001b[39m10.34    \u001b[39m | \u001b[39m164.0    \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-0.4862  \u001b[39m | \u001b[39m17.22    \u001b[39m | \u001b[39m15.37    \u001b[39m | \u001b[39m161.8    \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-0.5198  \u001b[39m | \u001b[39m1.24     \u001b[39m | \u001b[39m16.51    \u001b[39m | \u001b[39m166.3    \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-0.4819  \u001b[39m | \u001b[39m6.559    \u001b[39m | \u001b[39m10.56    \u001b[39m | \u001b[39m61.66    \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-0.4809  \u001b[39m | \u001b[39m10.18    \u001b[39m | \u001b[39m11.74    \u001b[39m | \u001b[39m156.2    \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-0.4815  \u001b[39m | \u001b[39m11.08    \u001b[39m | \u001b[39m3.909    \u001b[39m | \u001b[39m161.0    \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-0.4839  \u001b[39m | \u001b[39m14.43    \u001b[39m | \u001b[39m9.365    \u001b[39m | \u001b[39m170.5    \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-0.4853  \u001b[39m | \u001b[39m17.07    \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m173.6    \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-0.4815  \u001b[39m | \u001b[39m12.53    \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m153.7    \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-0.4985  \u001b[39m | \u001b[39m3.635    \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m72.08    \u001b[39m |\n",
      "=============================================================\n",
      "Best parameters:  {'max_depth': np.float64(8.136585510152898), 'min_samples_split': np.float64(4.150949076195745), 'n_estimators': np.float64(63.177204589032435)}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "# Split the training data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(['id','relevance'],axis=1).values, df_train['relevance'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "def rf_evaluate(n_estimators, max_depth, min_samples_split):\n",
    "    rf = RandomForestRegressor(n_estimators=int(n_estimators), \n",
    "                               max_depth=int(max_depth),\n",
    "                               min_samples_split=int(min_samples_split),\n",
    "                               random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    return -root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pbounds = {\n",
    "    'n_estimators': (50, 200),\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_split': (2, 20)\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=rf_evaluate,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    ")\n",
    "optimizer.maximize(init_points=10, n_iter=20)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d27c5efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with Bayesian Optimization:  0.48041488496620843\n"
     ]
    }
   ],
   "source": [
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf = BaggingRegressor(rf_best, n_estimators=45, max_samples=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"RMSE with Bayesian Optimization: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afb6e1",
   "metadata": {},
   "source": [
    "## Bayesian optimization WITH crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-0.4831  \u001b[39m | \u001b[39m8.116    \u001b[39m | \u001b[39m19.11    \u001b[39m | \u001b[39m159.8    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-0.4871  \u001b[39m | \u001b[39m12.37    \u001b[39m | \u001b[39m4.808    \u001b[39m | \u001b[39m73.4     \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-0.5115  \u001b[39m | \u001b[39m2.104    \u001b[39m | \u001b[39m17.59    \u001b[39m | \u001b[39m140.2    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-0.491   \u001b[39m | \u001b[39m14.45    \u001b[39m | \u001b[39m2.371    \u001b[39m | \u001b[39m195.5    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-0.4949  \u001b[39m | \u001b[39m16.82    \u001b[39m | \u001b[39m5.822    \u001b[39m | \u001b[39m77.27    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-0.4904  \u001b[39m | \u001b[39m4.485    \u001b[39m | \u001b[39m7.476    \u001b[39m | \u001b[39m128.7    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-0.4838  \u001b[39m | \u001b[39m9.207    \u001b[39m | \u001b[39m7.242    \u001b[39m | \u001b[39m141.8    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-0.5023  \u001b[39m | \u001b[39m3.65     \u001b[39m | \u001b[39m7.259    \u001b[39m | \u001b[39m105.0    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-0.4837  \u001b[39m | \u001b[39m9.665    \u001b[39m | \u001b[39m16.13    \u001b[39m | \u001b[39m79.95    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-0.4846  \u001b[39m | \u001b[39m10.77    \u001b[39m | \u001b[39m12.66    \u001b[39m | \u001b[39m56.97    \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-0.4846  \u001b[39m | \u001b[39m10.23    \u001b[39m | \u001b[39m12.39    \u001b[39m | \u001b[39m56.56    \u001b[39m |\n",
      "| \u001b[35m12       \u001b[39m | \u001b[35m-0.483   \u001b[39m | \u001b[35m7.39     \u001b[39m | \u001b[35m13.66    \u001b[39m | \u001b[35m71.27    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-0.4865  \u001b[39m | \u001b[39m5.07     \u001b[39m | \u001b[39m5.77     \u001b[39m | \u001b[39m64.63    \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-0.4965  \u001b[39m | \u001b[39m16.7     \u001b[39m | \u001b[39m2.132    \u001b[39m | \u001b[39m146.4    \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-0.511   \u001b[39m | \u001b[39m2.458    \u001b[39m | \u001b[39m10.88    \u001b[39m | \u001b[39m77.2     \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-0.4844  \u001b[39m | \u001b[39m10.91    \u001b[39m | \u001b[39m16.13    \u001b[39m | \u001b[39m74.29    \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-0.4845  \u001b[39m | \u001b[39m10.79    \u001b[39m | \u001b[39m12.06    \u001b[39m | \u001b[39m66.92    \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-0.483   \u001b[39m | \u001b[39m7.714    \u001b[39m | \u001b[39m18.12    \u001b[39m | \u001b[39m66.97    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-0.4906  \u001b[39m | \u001b[39m4.182    \u001b[39m | \u001b[39m14.15    \u001b[39m | \u001b[39m62.0     \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-0.4877  \u001b[39m | \u001b[39m14.36    \u001b[39m | \u001b[39m19.64    \u001b[39m | \u001b[39m82.39    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-0.4878  \u001b[39m | \u001b[39m14.57    \u001b[39m | \u001b[39m19.55    \u001b[39m | \u001b[39m67.25    \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-0.4838  \u001b[39m | \u001b[39m6.19     \u001b[39m | \u001b[39m18.56    \u001b[39m | \u001b[39m166.5    \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-0.4867  \u001b[39m | \u001b[39m13.66    \u001b[39m | \u001b[39m17.78    \u001b[39m | \u001b[39m164.5    \u001b[39m |\n",
      "| \u001b[35m24       \u001b[39m | \u001b[35m-0.483   \u001b[39m | \u001b[35m7.237    \u001b[39m | \u001b[35m12.35    \u001b[39m | \u001b[35m161.4    \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-0.5229  \u001b[39m | \u001b[39m1.729    \u001b[39m | \u001b[39m17.93    \u001b[39m | \u001b[39m161.2    \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-0.4842  \u001b[39m | \u001b[39m10.62    \u001b[39m | \u001b[39m15.47    \u001b[39m | \u001b[39m160.6    \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-0.4831  \u001b[39m | \u001b[39m8.448    \u001b[39m | \u001b[39m13.72    \u001b[39m | \u001b[39m165.6    \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-0.4836  \u001b[39m | \u001b[39m9.532    \u001b[39m | \u001b[39m17.76    \u001b[39m | \u001b[39m170.2    \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-0.4856  \u001b[39m | \u001b[39m12.09    \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m156.7    \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-0.4845  \u001b[39m | \u001b[39m10.68    \u001b[39m | \u001b[39m8.351    \u001b[39m | \u001b[39m162.8    \u001b[39m |\n",
      "=============================================================\n",
      "Best parameters using Bayesian Optimization with CV: {'max_depth': np.float64(7.2373847443209005), 'min_samples_split': np.float64(12.3499042860658), 'n_estimators': np.float64(161.4042914794713)}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define function for Bayesian Optimization\n",
    "def rf_evaluate(n_estimators, max_depth, min_samples_split):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 5-fold cross-validation with RMSE as scoring\n",
    "    cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    \n",
    "    return np.mean(cv_scores)  \n",
    "\n",
    "# Define the parameter bounds\n",
    "pbounds = {\n",
    "    'n_estimators': (50, 200),\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_split': (2, 20)\n",
    "}\n",
    "\n",
    "# Carry out Bayesian Optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=rf_evaluate,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=20)\n",
    "\n",
    "# Print best parameters\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best parameters using Bayesian Optimization with CV:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "733d4be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with Bayesian Optimization and CV:  0.4807862670864091\n"
     ]
    }
   ],
   "source": [
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf = BaggingRegressor(rf_best, n_estimators=45, max_samples=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "print(\"RMSE with Bayesian Optimization and CV: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78d1e9",
   "metadata": {},
   "source": [
    "## Knowledge-driven feature extraction: numbers and units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40cba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of optimized model (12.2) with Jaccard features & units:  0.5041539074387235\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Create a function to calculate Jaccard Similarity\n",
    "def jaccard_similarity(str1, str2):\n",
    "    set1 = set(str1.lower().split())\n",
    "    set2 = set(str2.lower().split())\n",
    "    return len(set1 & set2) / len(set1 | set2) if (set1 | set2) else 0\n",
    "\n",
    "# Read in the data\n",
    "df_train = pd.read_csv('DATA/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('DATA/product_descriptions.csv')\n",
    "df_all = pd.merge(df_train, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "# Calculate Jaccard Similarity features\n",
    "df_all['jaccard_title'] = df_all.apply(lambda x: jaccard_similarity(str(x['search_term']), str(x['product_title'])), axis=1)\n",
    "df_all['jaccard_description'] = df_all.apply(lambda x: jaccard_similarity(str(x['search_term']), str(x['product_description'])), axis=1)\n",
    "\n",
    "# Extract numbers and units from text\n",
    "def extract_numbers_units(text):\n",
    "    pattern = r\"\\d+(?:\\.\\d+)?\\s*\\w+|\\d+/\\d+\"  # Herkent \"8 ft.\", \"3/4\", \"12V\"\n",
    "    matches = re.findall(pattern, text.lower())\n",
    "    return \" \".join(matches) if matches else \"none\"\n",
    "\n",
    "# Add new features for numbers and units\n",
    "df_all['numbers_units_query'] = df_all['search_term'].map(extract_numbers_units)\n",
    "df_all['numbers_units_title'] = df_all['product_title'].map(extract_numbers_units)\n",
    "df_all['numbers_units_description'] = df_all['product_description'].map(extract_numbers_units)\n",
    "\n",
    "# Jaccard Similarity on numbers and units\n",
    "df_all['jaccard_numbers_title'] = df_all.apply(lambda x: jaccard_similarity(str(x['numbers_units_query']), str(x['numbers_units_title'])), axis=1)\n",
    "df_all['jaccard_numbers_description'] = df_all.apply(lambda x: jaccard_similarity(str(x['numbers_units_query']), str(x['numbers_units_description'])), axis=1)\n",
    "\n",
    "\n",
    "# Split the dataset, including Jaccard features and numbers/units\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_all.drop(['id', 'relevance', 'search_term', 'product_title', 'product_description', 'numbers_units_query', 'numbers_units_title', 'numbers_units_description'], axis=1), \n",
    "    df_all['relevance'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train with optimized Random Forest\n",
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf = BaggingRegressor(rf_best, n_estimators=45, max_samples=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"RMSE of optimized model (12.2) with Jaccard features & units: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63e04e",
   "metadata": {},
   "source": [
    "# Week 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2fd470",
   "metadata": {},
   "source": [
    "## Inspect feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd9ffd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=7, min_samples_split=12, n_estimators=161,\n",
       "                      random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=7, min_samples_split=12, n_estimators=161,\n",
       "                      random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=7, min_samples_split=12, n_estimators=161,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RandomForest without Bagging to inspect feature importance\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c8cbd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feature  Importance\n",
      "1                jaccard_title    0.541209\n",
      "0                  product_uid    0.355029\n",
      "2          jaccard_description    0.065059\n",
      "3        jaccard_numbers_title    0.021770\n",
      "4  jaccard_numbers_description    0.016932\n"
     ]
    }
   ],
   "source": [
    "feature_names = X_train.columns\n",
    "feature_importance = rf.feature_importances_\n",
    "\n",
    "# Create DataFrame and sort by importance\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Show top 5 most important features\n",
    "print(importance_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f35172b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of optimized model (12.2) with Jaccard features & units & TF-IDF vectorizer:  0.5033566075542595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a function to calculate Jaccard Similarity\n",
    "def jaccard_similarity(str1, str2):\n",
    "    set1 = set(str1.lower().split())\n",
    "    set2 = set(str2.lower().split())\n",
    "    return len(set1 & set2) / len(set1 | set2) if (set1 | set2) else 0\n",
    "\n",
    "# Read in the data\n",
    "df_train = pd.read_csv('DATA/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('DATA/product_descriptions.csv')\n",
    "df_all = pd.merge(df_train, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "# Calculate Jaccard Similarity features\n",
    "df_all['jaccard_title'] = df_all.apply(lambda x: jaccard_similarity(str(x['search_term']), str(x['product_title'])), axis=1)\n",
    "df_all['jaccard_description'] = df_all.apply(lambda x: jaccard_similarity(str(x['search_term']), str(x['product_description'])), axis=1)\n",
    "\n",
    "# Function to extract numbers and units from text\n",
    "def extract_numbers_units(text):\n",
    "    pattern = r\"\\d+(?:\\.\\d+)?\\s*\\w+|\\d+/\\d+\"  # Herkent \"8 ft.\", \"3/4\", \"12V\"\n",
    "    matches = re.findall(pattern, text.lower())\n",
    "    return \" \".join(matches) if matches else \"none\"\n",
    "\n",
    "# Add new features for numbers and units\n",
    "df_all['numbers_units_query'] = df_all['search_term'].map(extract_numbers_units)\n",
    "df_all['numbers_units_title'] = df_all['product_title'].map(extract_numbers_units)\n",
    "df_all['numbers_units_description'] = df_all['product_description'].map(extract_numbers_units)\n",
    "\n",
    "# Jaccard Similarity on numbers and units\n",
    "df_all['jaccard_numbers_title'] = df_all.apply(lambda x: jaccard_similarity(str(x['numbers_units_query']), str(x['numbers_units_title'])), axis=1)\n",
    "df_all['jaccard_numbers_description'] = df_all.apply(lambda x: jaccard_similarity(str(x['numbers_units_query']), str(x['numbers_units_description'])), axis=1)\n",
    "\n",
    "# TF-IDF vectorizer for text features\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=500)\n",
    "\n",
    "# Transform text features to TF-IDF scores\n",
    "tfidf_query = tfidf_vectorizer.fit_transform(df_all['search_term'])\n",
    "tfidf_title = tfidf_vectorizer.transform(df_all['product_title'])\n",
    "\n",
    "# Transform to DataFrames\n",
    "tfidf_query_df = pd.DataFrame(tfidf_query.toarray(), columns=[f\"query_tfidf_{i}\" for i in range(tfidf_query.shape[1])])\n",
    "tfidf_title_df = pd.DataFrame(tfidf_title.toarray(), columns=[f\"title_tfidf_{i}\" for i in range(tfidf_title.shape[1])])\n",
    "\n",
    "# Add TF-IDF features to dataset\n",
    "df_all = pd.concat([df_all.reset_index(drop=True), tfidf_query_df, tfidf_title_df], axis=1)\n",
    "\n",
    "# Remove irrelevant text features \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_all.drop(['id', 'relevance', 'search_term', 'product_title', 'product_description', 'numbers_units_query', 'numbers_units_title', 'numbers_units_description'], axis=1), \n",
    "    df_all['relevance'], \n",
    "    test_size=0.2, \n",
    "    random_state=42)\n",
    "\n",
    "# Train optimized Random Forest with Jaccard features & units & TF-IDF vectorizer\n",
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf = BaggingRegressor(rf_best, n_estimators=45, max_samples=0.1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"RMSE of optimized model (12.2) with Jaccard features & units & TF-IDF vectorizer: \", root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4058ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=7, min_samples_split=12, n_estimators=161,\n",
       "                      random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=7, min_samples_split=12, n_estimators=161,\n",
       "                      random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=7, min_samples_split=12, n_estimators=161,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RandomForest without Bagging to inspect feature importance\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61937185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most impactful features:\n",
      "                   Feature  Importance\n",
      "1            jaccard_title    0.502802\n",
      "0              product_uid    0.282506\n",
      "2      jaccard_description    0.020767\n",
      "3    jaccard_numbers_title    0.005161\n",
      "168        query_tfidf_163    0.004483\n",
      "Top 5 least impactful features:\n",
      "             Feature  Importance\n",
      "991  title_tfidf_486         0.0\n",
      "988  title_tfidf_483         0.0\n",
      "219  query_tfidf_214         0.0\n",
      "214  query_tfidf_209         0.0\n",
      "44    query_tfidf_39         0.0\n"
     ]
    }
   ],
   "source": [
    "feature_names = X_train.columns\n",
    "\n",
    "feature_importance = rf.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Top 5 most impactful features:\")\n",
    "print(importance_df.head(5))\n",
    "print(\"Top 5 least impactful features:\")\n",
    "print(importance_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63593f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE after removing low importance features:  0.5030339174163405\n"
     ]
    }
   ],
   "source": [
    "# Remove weak features with low importance\n",
    "low_importance_features = importance_df[importance_df['Importance'] < 0.001]['Feature'].tolist()\n",
    "X_train_filtered = X_train.drop(columns=low_importance_features)\n",
    "X_test_filtered = X_test.drop(columns=low_importance_features)\n",
    "\n",
    "# Retrain model without low importance features\n",
    "rf_final = RandomForestRegressor(\n",
    "    n_estimators=int(best_params['n_estimators']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_samples_split=int(best_params['min_samples_split']),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_final.fit(X_train_filtered, y_train)\n",
    "y_pred_final = rf_final.predict(X_test_filtered)\n",
    "\n",
    "# Calculate new RMSE\n",
    "print(\"RMSE after removing low importance features: \", root_mean_squared_error(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0f2f31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term behind query_tfidf_163 is: amp\n"
     ]
    }
   ],
   "source": [
    "# retrieve the feature names from the TF-IDF vectorizer\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "# get the term corresponding to the index 163\n",
    "query_term = tfidf_feature_names[163]\n",
    "\n",
    "print(\"The term behind query_tfidf_163 is:\", query_term)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
